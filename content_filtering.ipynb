{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c586f535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b01d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5152b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "animes_df = pd.read_csv(\"data/animes.csv\")\n",
    "ratings_df = pd.read_csv(\"data/reviews.csv\")\n",
    "profiles_df = pd.read_csv(\"data/profiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "646d5f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     uid  ...                                               link\n",
      "0  28891  ...  https://myanimelist.net/anime/28891/Haikyuu_Se...\n",
      "1  23273  ...  https://myanimelist.net/anime/23273/Shigatsu_w...\n",
      "2  34599  ...  https://myanimelist.net/anime/34599/Made_in_Abyss\n",
      "3   5114  ...  https://myanimelist.net/anime/5114/Fullmetal_A...\n",
      "4  31758  ...  https://myanimelist.net/anime/31758/Kizumonoga...\n",
      "\n",
      "[5 rows x 12 columns]\n",
      "      uid  ...                                           link\n",
      "0  255938  ...  https://myanimelist.net/reviews.php?id=255938\n",
      "1  259117  ...  https://myanimelist.net/reviews.php?id=259117\n",
      "2  253664  ...  https://myanimelist.net/reviews.php?id=253664\n",
      "3    8254  ...    https://myanimelist.net/reviews.php?id=8254\n",
      "4  291149  ...  https://myanimelist.net/reviews.php?id=291149\n",
      "\n",
      "[5 rows x 7 columns]\n",
      "           profile  ...                                             link\n",
      "0   DesolatePsyche  ...   https://myanimelist.net/profile/DesolatePsyche\n",
      "1        baekbeans  ...        https://myanimelist.net/profile/baekbeans\n",
      "2             skrn  ...             https://myanimelist.net/profile/skrn\n",
      "3     edgewalker00  ...     https://myanimelist.net/profile/edgewalker00\n",
      "4  aManOfCulture99  ...  https://myanimelist.net/profile/aManOfCulture99\n",
      "\n",
      "[5 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# See the first 5 rows\n",
    "print(animes_df.head())\n",
    "print(ratings_df.head())\n",
    "print(profiles_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bc475ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year     score  Action  Adventure  ...  Thriller  Vampire  Yaoi  Yuri\n",
      "0  0.997031  0.955580       0          0  ...         0        0     0     0\n",
      "1  0.996536  0.956663       0          0  ...         0        0     0     0\n",
      "2  0.998021  0.956663       0          1  ...         0        0     0     0\n",
      "3  0.994062  1.000000       1          1  ...         0        0     0     0\n",
      "4  0.998021  0.956663       1          0  ...         0        1     0     0\n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract start year from aired\n",
    "animes_df[\"year\"] = animes_df[\"aired\"].str.extract(r'(\\d{4})').astype(float)\n",
    "\n",
    "# Convert stringified lists to actual lists\n",
    "import ast\n",
    "animes_df['genre'] = animes_df['genre'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "# One-hot encode genres\n",
    "genre_dummies = animes_df[\"genre\"].str.join('|').str.get_dummies()\n",
    "\n",
    "# Select numeric features\n",
    "num_features = animes_df[[\"year\", \"score\"]].fillna(0)\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = MinMaxScaler()\n",
    "num_features = pd.DataFrame(\n",
    "    scaler.fit_transform(num_features),\n",
    "    columns=num_features.columns,\n",
    "    index=animes_df.index\n",
    ")\n",
    "\n",
    "# Combine everything\n",
    "item_train = pd.concat([num_features, genre_dummies], axis=1)\n",
    "print(item_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2aad4db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'year': 0.9946066303809996, 'score': 0.8813109425785483, 'Action': 0.4, 'Adventure': 0.4, 'Cars': 0.0, 'Comedy': 0.45, 'Dementia': 0.0, 'Demons': 0.05, 'Drama': 0.45, 'Ecchi': 0.0, 'Fantasy': 0.25, 'Game': 0.05, 'Harem': 0.05, 'Hentai': 0.0, 'Historical': 0.1, 'Horror': 0.1, 'Josei': 0.05, 'Kids': 0.0, 'Magic': 0.0, 'Martial Arts': 0.05, 'Mecha': 0.05, 'Military': 0.05, 'Music': 0.1, 'Mystery': 0.25, 'Parody': 0.0, 'Police': 0.05, 'Psychological': 0.15, 'Romance': 0.45, 'Samurai': 0.0, 'School': 0.1, 'Sci-Fi': 0.1, 'Seinen': 0.15, 'Shoujo': 0.05, 'Shoujo Ai': 0.0, 'Shounen': 0.3, 'Shounen Ai': 0.0, 'Slice of Life': 0.3, 'Space': 0.0, 'Sports': 0.0, 'Super Power': 0.15, 'Supernatural': 0.4, 'Thriller': 0.0, 'Vampire': 0.05, 'Yaoi': 0.0, 'Yuri': 0.0}\n"
     ]
    }
   ],
   "source": [
    "## --- User features ---\n",
    "import ast\n",
    "\n",
    "# Convert stringified lists to real lists of ints\n",
    "def parse_favorites(x):\n",
    "    try:\n",
    "        return [int(a) for a in ast.literal_eval(x)]\n",
    "    except:\n",
    "        return []  # fallback for malformed entries\n",
    "\n",
    "profiles_df[\"favorites_anime\"] = profiles_df[\"favorites_anime\"].apply(parse_favorites)\n",
    "# Step 2: Build user_train\n",
    "user_features = []\n",
    "# Create a mapping from anime UID to row index in item_train\n",
    "anime_id_to_idx = {uid: idx for idx, uid in enumerate(animes_df[\"uid\"])}\n",
    "\n",
    "for _, row in profiles_df.iterrows():\n",
    "    favs = row[\"favorites_anime\"]\n",
    "    \n",
    "    # Get indices of these anime in item_train\n",
    "    indices = [anime_id_to_idx[uid] for uid in favs if uid in anime_id_to_idx]\n",
    "    \n",
    "    if indices:\n",
    "        # Average features of the anime to get user preference vector\n",
    "        user_vec = item_train.iloc[indices].mean(axis=0)\n",
    "    else:\n",
    "        # If no valid favorites, use zero vector\n",
    "        user_vec = np.zeros(item_train.shape[1])\n",
    "    \n",
    "    user_features.append(user_vec)\n",
    "\n",
    "# Create user_train DataFrame\n",
    "user_train = pd.DataFrame(user_features, index=profiles_df[\"profile\"])\n",
    "print(user_train.iloc[0].to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea21d5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "user_train = user_train.fillna(0)\n",
    "print(item_train.isna().sum().sum())   # total NaNs in item_train\n",
    "print(user_train.isna().sum().sum())   # total NaNs in user_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcb19f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         uid  ...                                               link\n",
      "17495  31933  ...  https://myanimelist.net/anime/31933/JoJo_no_Ki...\n",
      "723    31933  ...  https://myanimelist.net/anime/31933/JoJo_no_Ki...\n",
      "858      154  ...      https://myanimelist.net/anime/154/Shaman_King\n",
      "19073    154  ...      https://myanimelist.net/anime/154/Shaman_King\n",
      "5395     969  ...  https://myanimelist.net/anime/969/Tsubasa_Chro...\n",
      "14      4181  ...  https://myanimelist.net/anime/4181/Clannad__Af...\n",
      "3091    4181  ...  https://myanimelist.net/anime/4181/Clannad__Af...\n",
      "8174   36491  ...  https://myanimelist.net/anime/36491/Doupo_Cang...\n",
      "16185   2486  ...  https://myanimelist.net/anime/2486/Rumiko_Taka...\n",
      "853      479  ...  https://myanimelist.net/anime/479/Ueki_no_Housoku\n",
      "\n",
      "[10 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "top_n = 10\n",
    "all_recommendations = {}\n",
    "\n",
    "for idx, profile in enumerate(user_train.index):\n",
    "    user_vec = user_train.iloc[idx].values.reshape(1, -1)\n",
    "    sims = cosine_similarity(user_vec, item_train.values)[0]\n",
    "    top_idx = sims.argsort()[-top_n:][::-1]\n",
    "    all_recommendations[profile] = animes_df.iloc[top_idx][['uid','title','score','link']]\n",
    "\n",
    "# Example: show recommendations for first user\n",
    "print(all_recommendations[user_train.index[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6574d605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99460663 0.88131094 0.4        0.4        0.         0.45\n",
      "  0.         0.05       0.45       0.         0.25       0.05\n",
      "  0.05       0.         0.1        0.1        0.05       0.\n",
      "  0.         0.05       0.05       0.05       0.1        0.25\n",
      "  0.         0.05       0.15       0.45       0.         0.1\n",
      "  0.1        0.15       0.05       0.         0.3        0.\n",
      "  0.3        0.         0.         0.15       0.4        0.\n",
      "  0.05       0.         0.        ]]\n",
      "17496. JoJo no Kimyou na Bouken Part 4: Diamond wa Kudakenai (score: 8.6) - https://myanimelist.net/anime/31933/JoJo_no_Kimyou_na_Bouken_Part_4__Diamond_wa_Kudakenai\n",
      "724. JoJo no Kimyou na Bouken Part 4: Diamond wa Kudakenai (score: 8.6) - https://myanimelist.net/anime/31933/JoJo_no_Kimyou_na_Bouken_Part_4__Diamond_wa_Kudakenai\n",
      "859. Shaman King (score: 7.82) - https://myanimelist.net/anime/154/Shaman_King\n",
      "19074. Shaman King (score: 7.82) - https://myanimelist.net/anime/154/Shaman_King\n",
      "5396. Tsubasa Chronicle 2nd Season (score: 7.66) - https://myanimelist.net/anime/969/Tsubasa_Chronicle_2nd_Season\n",
      "15. Clannad: After Story (score: 8.97) - https://myanimelist.net/anime/4181/Clannad__After_Story\n",
      "3092. Clannad: After Story (score: 8.97) - https://myanimelist.net/anime/4181/Clannad__After_Story\n",
      "8175. Doupo Cangqiong (score: 7.48) - https://myanimelist.net/anime/36491/Doupo_Cangqiong\n",
      "16186. Rumiko Takahashi Anthology (score: 7.29) - https://myanimelist.net/anime/2486/Rumiko_Takahashi_Anthology\n",
      "854. Ueki no Housoku (score: 7.82) - https://myanimelist.net/anime/479/Ueki_no_Housoku\n"
     ]
    }
   ],
   "source": [
    "# Get user vector (1 x num_features)\n",
    "user_vec = user_train.iloc[0].values.reshape(1, -1)\n",
    "print(user_vec)\n",
    "\n",
    "# Compute cosine similarity with all items\n",
    "similarities = cosine_similarity(user_vec, item_train.values)[0]\n",
    "\n",
    "# Get indices of top-N most similar items\n",
    "top_n = 10\n",
    "top_idx = similarities.argsort()[-top_n:][::-1]\n",
    "\n",
    "# Show recommended anime\n",
    "recommended_anime = animes_df.iloc[top_idx][['uid','title','genre','score','link']]\n",
    "# Print nicely\n",
    "for i, row in recommended_anime.iterrows():\n",
    "    print(f\"{i+1}. {row['title']} (score: {row['score']}) - {row['link']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d3db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
